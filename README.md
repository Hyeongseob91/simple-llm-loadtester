# LLM Loadtest

> LLM ì„œë¹™ ì„œë²„ ë¶€í•˜ í…ŒìŠ¤íŠ¸ ë„êµ¬

vLLM, SGLang, Ollama ë“± OpenAI-compatible API ì„œë²„ì˜ ë¶€í•˜ í…ŒìŠ¤íŠ¸ë¥¼ ìˆ˜í–‰í•˜ê³ , ê²°ê³¼ë¥¼ Web ëŒ€ì‹œë³´ë“œì—ì„œ ì‹œê°í™”í•©ë‹ˆë‹¤.

## ì£¼ìš” ê¸°ëŠ¥

- **ë¶€í•˜ í…ŒìŠ¤íŠ¸**: ë‹¤ì–‘í•œ ë™ì‹œì„± ë ˆë²¨ì—ì„œ LLM ì„œë²„ ì„±ëŠ¥ ì¸¡ì •
- **LLM íŠ¹í™” ë©”íŠ¸ë¦­**: TTFT, TPOT, ITL, Throughput, p95/p99
- **Goodput**: SLO ê¸°ë°˜ í’ˆì§ˆ ì§€í‘œ (ìš”ì²­ ì¤‘ ì„ê³„ê°’ ë§Œì¡± ë¹„ìœ¨)
- **Web ëŒ€ì‹œë³´ë“œ**: ê²°ê³¼ ì‹œê°í™”, ë¹„êµ, íˆìŠ¤í† ë¦¬ ê´€ë¦¬
- **ì–´ëŒ‘í„° íŒ¨í„´**: OpenAI-compatible, Triton (ì˜ˆì •)

## ë¹ ë¥¸ ì‹œì‘

### Docker Compose (ê¶Œì¥)

```bash
# ì „ì²´ ì„œë¹„ìŠ¤ ì‹œì‘
docker compose up -d

# ì ‘ì†
# - Web UI: http://localhost:5050
# - API: http://localhost:8085
```

### CLI ì„¤ì¹˜

```bash
cd cli
pip install -e .

# ê¸°ë³¸ ë¶€í•˜ í…ŒìŠ¤íŠ¸
llm-loadtest run \
  --server http://localhost:8000 \
  --model qwen3-14b \
  --concurrency 1,10,50 \
  --num-prompts 100 \
  --output result.json

# Goodput ì¸¡ì •
llm-loadtest run \
  --server http://localhost:8000 \
  --model qwen3-14b \
  --concurrency 50 \
  --goodput ttft:500,tpot:50

# ì‹œìŠ¤í…œ ì •ë³´
llm-loadtest info
llm-loadtest gpu
```

## í”„ë¡œì íŠ¸ êµ¬ì¡°

```
llm-loadtest/
â”œâ”€â”€ core/                    # í•µì‹¬ ë¡œì§
â”‚   â”œâ”€â”€ load_generator.py    # asyncio ê¸°ë°˜ ë¶€í•˜ ìƒì„±
â”‚   â”œâ”€â”€ metrics.py           # TTFT, TPOT, Goodput ê³„ì‚°
â”‚   â””â”€â”€ models.py            # ë°ì´í„° ëª¨ë¸
â”‚
â”œâ”€â”€ adapters/                # ì„œë²„ ì–´ëŒ‘í„°
â”‚   â”œâ”€â”€ base.py              # ì–´ëŒ‘í„° ì¸í„°í˜ì´ìŠ¤
â”‚   â””â”€â”€ openai_compat.py     # vLLM, SGLang, Ollama ì§€ì›
â”‚
â”œâ”€â”€ cli/                     # CLI ë„êµ¬
â”œâ”€â”€ api/                     # FastAPI ë°±ì—”ë“œ
â”œâ”€â”€ web/                     # Next.js ëŒ€ì‹œë³´ë“œ
â””â”€â”€ docker/                  # Docker ì„¤ì •
```

## CLI ëª…ë ¹ì–´

### `llm-loadtest run`

ë¶€í•˜ í…ŒìŠ¤íŠ¸ ì‹¤í–‰

```bash
llm-loadtest run \
  --server http://localhost:8000 \    # ì„œë²„ URL
  --model qwen3-14b \                  # ëª¨ë¸ëª…
  --concurrency 1,10,50,100 \          # ë™ì‹œì„± ë ˆë²¨
  --num-prompts 100 \                  # ìš”ì²­ ìˆ˜
  --input-len 256 \                    # ì…ë ¥ í† í° ê¸¸ì´
  --output-len 128 \                   # ì¶œë ¥ í† í° ê¸¸ì´
  --stream \                           # ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ
  --goodput ttft:500,tpot:50 \         # Goodput SLO
  --output result.json                 # ê²°ê³¼ íŒŒì¼
```

### `llm-loadtest info`

ì‹œìŠ¤í…œ ì •ë³´ ì¶œë ¥

### `llm-loadtest gpu`

GPU ìƒíƒœ í™•ì¸

## API ì—”ë“œí¬ì¸íŠ¸

| Method | Endpoint | ì„¤ëª… |
|--------|----------|------|
| POST | `/api/v1/benchmark/run` | ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ |
| GET | `/api/v1/benchmark/run/:id` | ì‹¤í–‰ ìƒíƒœ ì¡°íšŒ |
| GET | `/api/v1/benchmark/result/:id` | ê²°ê³¼ ì¡°íšŒ |
| GET | `/api/v1/benchmark/history` | íˆìŠ¤í† ë¦¬ ëª©ë¡ |
| POST | `/api/v1/benchmark/compare` | ê²°ê³¼ ë¹„êµ |
| DELETE | `/api/v1/benchmark/run/:id` | ê²°ê³¼ ì‚­ì œ |

## ë©”íŠ¸ë¦­ ì •ì˜

| ë©”íŠ¸ë¦­ | ì •ì˜ |
|--------|------|
| **TTFT** | Time To First Token - ì²« í† í°ê¹Œì§€ ì‹œê°„ |
| **TPOT** | Time Per Output Token - ì¶œë ¥ í† í°ë‹¹ ì‹œê°„ |
| **ITL** | Inter-Token Latency - í† í° ê°„ ì§€ì—° |
| **E2E** | End-to-End Latency - ì „ì²´ ì‘ë‹µ ì‹œê°„ |
| **Throughput** | ì´ˆë‹¹ ìƒì„± í† í° ìˆ˜ (tokens/s) |
| **Goodput** | SLO ë§Œì¡± ìš”ì²­ ë¹„ìœ¨ (%) |

## Goodput

NVIDIA GenAI-Perfì—ì„œ ì œì•ˆí•œ ê°œë…ìœ¼ë¡œ, ë‹¨ìˆœ ì²˜ë¦¬ëŸ‰ì´ ì•„ë‹Œ **SLOë¥¼ ë§Œì¡±í•˜ëŠ” ìš”ì²­ì˜ ë¹„ìœ¨**ì„ ì¸¡ì •í•©ë‹ˆë‹¤.

```bash
# TTFT < 500ms, TPOT < 50msë¥¼ ë§Œì¡±í•˜ëŠ” ìš”ì²­ ë¹„ìœ¨ ì¸¡ì •
llm-loadtest run \
  --server http://localhost:8000 \
  --model qwen3-14b \
  --goodput ttft:500,tpot:50
```

ì¶œë ¥ ì˜ˆì‹œ:
```
Goodput: 87.0% (87/100 requests met SLO)
  - TTFT < 500ms: 92/100
  - TPOT < 50ms: 89/100
```

## ì§€ì› ì„œë²„

| ì„œë²„ | ì–´ëŒ‘í„° | ìƒíƒœ |
|------|--------|------|
| vLLM | `openai` | âœ… ì§€ì› |
| SGLang | `openai` | âœ… ì§€ì› |
| Ollama | `openai` | âœ… ì§€ì› |
| LMDeploy | `openai` | âœ… ì§€ì› |
| Triton | `triton` | ğŸš§ ì˜ˆì • |
| TensorRT-LLM | `trtllm` | ğŸš§ ì˜ˆì • |

## ê°œë°œ

### ë¡œì»¬ ê°œë°œ

```bash
# CLI ê°œë°œ
cd cli
pip install -e ".[dev]"

# API ê°œë°œ
cd api
pip install -e ".[dev]"
uvicorn llm_loadtest_api.main:app --reload --port 8080

# Web ê°œë°œ
cd web
npm install
npm run dev
```

### í…ŒìŠ¤íŠ¸

```bash
# CLI í…ŒìŠ¤íŠ¸
cd cli && pytest tests/

# API í…ŒìŠ¤íŠ¸
cd api && pytest tests/

# Web í…ŒìŠ¤íŠ¸
cd web && npm run lint
```

## ë¼ì´ì„ ìŠ¤

MIT License
